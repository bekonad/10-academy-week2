# -*- coding: utf-8 -*-
"""Week2_Fintech_Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16seJsg8AUO-hPFZqdqwVLwsu7JlkUmoe
"""

!pip install google-play-scraper

!pip help install

from google_play_scraper import reviews, Sort
import pandas as pd
import datetime

# Define apps (assumed IDs; verify with facilitators if errors occur)
apps = [
    {"name": "Commercial Bank of Ethiopia", "id": "com.combanketh.mobilebanking"},
    {"name": "Bank of Abyssinia", "id": "com.boa.boaMobileBanking"},
    {"name": "Dashen Bank", "id": "com.dashen.dashensuperapp"}
]

all_reviews = []

for app in apps:
    try:
        result, _ = reviews(
            app["id"],
            lang="en",
            country="et",
            sort=Sort.NEWEST,
            count=400
        )
        for review in result:
            all_reviews.append({
                "review": review["content"],
                "rating": review["score"],                                                                                                                              "date": review["at"].strftime("%Y-%m-%d"),
                "bank": app["name"],
                "source": "Google Play"
            })
    except Exception as e:
        print(f"Error scraping {app['name']}: {e}")

# Convert to DataFrame
df = pd.DataFrame(all_reviews)
print(f"Collected {len(df)} reviews")
df.head()

# Preprocessing
df = df.drop_duplicates(subset=["review", "date", "bank"])  # Remove duplicates
df = df.dropna(subset=["review", "rating"])  # Drop missing critical fields
df["date"] = pd.to_datetime(df["date"]).dt.strftime("%Y-%m-%d")  # Normalize dates

# Check data quality
print(f"Total reviews after cleaning: {len(df)}")
print(f"Missing data:\n{df.isnull().sum()}")

# Save to CSV and download
df.to_csv("reviews.csv", index=False)
from google.colab import files
files.download("reviews.csv")